---
title: "Regelung zur Nutzung generativer KI im Dienstbetrieb der Bundeswehr"
date: 2026-02-04
---

# {{ page.title }}
{:.no_toc}

Christian Ullrich  
{{ page.date }}

## Quellen

- [Christian Ullrich: "ChatGPT für Verbesserungs- und Innovationsvorschläge"](https://www.intrenion.com/chatgpt-fuer-verbesserungs-und-innovationsvorschlaege)

## Ausgangslage

1. Seit Ende 2023 nimmt die Zahl der Softwarelösungen im Bereich der generativen KI stark zu.
2. ChatGPT hat sich als besonders schnell wachsender und weit verbreiteter Online-Service etabliert.
3. Bürokratische und langsame Innovations- und Beschaffungssysteme verzögern die Integration einer allgemein verfügbaren Lösung generativer KI in der Bundeswehr.
4. Unter den gegenwärtigen Bedingungen könnte die Einführung einer generativen KI-Lösung für das gesamte Personal fünf bis zehn Jahre dauern.
5. Berichte von Zugführern und Kompaniechefs zeigen, dass viele Soldaten ChatGPT bereits nutzen.
6. Die Nutzung erfolgt insbesondere bei der Erstellung dienstlicher Schriftstücke.
7. Diese Nutzung erfolgt ohne offizielle Regelung oder Anleitung seitens der Bundeswehr.
8. Das Fehlen klarer Vorgaben schafft einen rechtlichen Graubereich.

## Einordnung

1. Die langsamen Innovations- und Beschaffungsprozesse der Bundeswehr stehen im strukturellen Widerspruch zur schnellen Marktdynamik generativer KI.
2. Die fehlende offizielle Einführung einer generativen KI-Lösung führt dazu, dass Soldaten auf allgemein verfügbare Werkzeuge außerhalb geregelter Rahmenbedingungen zurückgreifen.
3. Die Nutzung ohne Regelung erzeugt rechtliche Unsicherheit, da keine klaren Grenzen für zulässige Anwendungen im dienstlichen Kontext festgelegt sind.
4. Ohne verbindliche Vorgaben können Sicherheits- und Datenschutzanforderungen beim Umgang mit sensiblen Informationen nicht zuverlässig eingehalten werden.
5. Die derzeitige Praxis begünstigt eine uneinheitliche Nutzung zwischen den Dienststellen, da Standards und Verantwortlichkeiten fehlen.
6. Die Verzögerung bei der Bereitstellung offizieller Lösungen verstärkt die Abhängigkeit von informellen und nicht kontrollierten Anwendungen.

## Konsequenz

1. Ohne eine offizielle Regelung bleibt die Nutzung generativer KI im Dienstbetrieb ein rechtlicher Graubereich.
2. Ohne verbindliche Vorgaben lassen sich Sicherheits- und Datenschutzrisiken nicht systematisch begrenzen.
3. Ohne Standardisierung entsteht eine dauerhaft uneinheitliche Nutzung generativer KI zwischen den Dienststellen.
4. Ohne klare Verantwortlichkeiten bleibt unklar, wer für Fehler oder Fehlanwendungen generierter Inhalte haftet.
5. Ohne zeitnahe Regelung verstärkt sich die Abhängigkeit von informellen und nicht kontrollierten Werkzeugen.
6. Ohne offizielle Leitlinien steigt das Risiko, dass sensible Informationen unbeabsichtigt in externe Systeme gelangen.

## Entscheidungen

1. Wir entscheiden, zeitnah eine Dienstvorschrift zur Nutzung generativer KI im Dienstbetrieb zu erlassen, weil dadurch klare rechtliche Handlungsgrenzen für Soldaten, statt die Nutzung weiterhin ungeregelt im Graubereich zu belassen und akzeptieren, dass die Erstellung und Abstimmung einer solchen Vorschrift kurzfristig zusätzlichen Aufwand verursacht.
2. Wir entscheiden, die Nutzung generativer KI auf klar definierte dienstliche Anwendungsfälle zu begrenzen, weil dadurch kontrollierbare Einsatzfelder mit reduziertem Sicherheitsrisiko entstehen, statt generative KI ohne Einschränkung für alle Zwecke zuzulassen, und akzeptieren, dass dadurch potenziell nützliche Einsatzmöglichkeiten zunächst ausgeschlossen werden.
3. Wir entscheiden, verbindliche Sicherheits- und Datenschutzvorgaben für den Umgang mit generativer KI festzulegen, weil dadurch ein operativer Schutz sensibler Informationen gewährleistet wird, statt auf individuelle Einschätzungen der Nutzer zu vertrauen, und akzeptieren, dass dies die Nutzung in bestimmten Fällen verlangsamt oder einschränkt.
4. Wir entscheiden, Verantwortlichkeiten für die Nutzung und die Ergebnisse generierter Inhalte eindeutig bei den jeweiligen Nutzern zu verankern, weil dadurch klare Haftungs- und Zuständigkeitsstrukturen, statt unklare Verantwortungslagen bei Fehlanwendungen zu akzeptieren, und akzeptieren, dass dies die persönliche Risikoabwägung der Nutzer erhöht.
5. Wir entscheiden, eine einheitliche Standardisierung der Nutzung generativer KI über alle Einheiten hinweg vorzugeben, weil dadurch konsistente Verfahren und weniger Unsicherheit entstehen, statt unterschiedliche lokale Praktiken zu tolerieren und akzeptieren, dass dies die Autonomie einzelner Dienststellen bei der Werkzeugauswahl reduziert.
